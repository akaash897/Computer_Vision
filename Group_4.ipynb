{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obCJOGilQ1Fc"
      },
      "source": [
        "Computer Vision Project:CSL7360\n",
        "\n",
        "Team Members:\n",
        "1)Akaash Chatterjee - M24CSE002\n",
        "\n",
        "2)Alok Dutta - M24CSE032\n",
        "\n",
        "3)Vishwanath Singh - M24CSE030\n",
        "\n",
        "4)Prathmesh Chintamani Gosavi - M24CSA023\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqtmJuHUWjwA"
      },
      "source": [
        "Topic :Comparative Assessment of Resolution Enhancement Models for Satellite Images\n",
        "======================================\n",
        "This code implements and compares various image enhancement techniques:\n",
        "1. Traditional interpolation methods (bicubic, lanczos)\n",
        "2. Deep learning-based super-resolution\n",
        "3. Wavelet-based enhancement\n",
        "4. Wiener filter deblurring\n",
        "5. Novel hybrid approaches (Wavelet-SR, Wiener-SR)\n",
        "\n",
        "Each technique is evaluated using multiple metrics on the UC Merced Land Use dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY_QBQOrIYq1"
      },
      "source": [
        "# 1) Downloading and Importing all Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNzFyPxkHY9Q",
        "outputId": "0200e4b2-5109-4619-c251-cd7454dab3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pywavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from pywavelets) (2.0.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.33.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pywavelets, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pywavelets-1.8.0 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pywavelets streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eNEzWGlIP_2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, BatchNormalization, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import pywt\n",
        "from scipy.signal import wiener\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRKnl6BcIhw9"
      },
      "source": [
        "#Data Loading and Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en3MKVxpIX4M"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "DATASET_URL = \"http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip\"\n",
        "DATA_DIR = \"UC_Merced_Dataset\"\n",
        "DATASET_PATH = \"UC_Merced_Dataset/UCMerced_LandUse/Images\"\n",
        "SELECTED_CATEGORIES = ['agricultural', 'baseballdiamond', 'beach', 'buildings', 'forest',\n",
        "                       'airplane', 'freeway', 'golfcourse',\n",
        "                       'harbor',  'mobilehomepark']  # Selected for consistent testing\n",
        "SAMPLE_COUNT = 1000  # Reduced to manage memory usage\n",
        "LR_SIZE = 128  # Low-resolution size\n",
        "HR_SIZE = 256  # High-resolution size\n",
        "BATCH_SIZE = 16  # Batch size for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3exFfs58IoIs"
      },
      "outputs": [],
      "source": [
        "# Create a results directory\n",
        "RESULTS_DIR = \"enhancement_results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "def download_uc_merced():\n",
        "    \"\"\"Download and extract the UC Merced Land Use dataset\"\"\"\n",
        "    if not os.path.exists(DATA_DIR):\n",
        "        os.makedirs(DATA_DIR)\n",
        "        print(\"Downloading UC Merced dataset...\")\n",
        "        response = requests.get(DATASET_URL, stream=True)\n",
        "        zip_path = os.path.join(DATA_DIR, \"UCMerced_LandUse.zip\")\n",
        "\n",
        "        with open(zip_path, \"wb\") as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(DATA_DIR)\n",
        "        os.remove(zip_path)\n",
        "        print(\"UC Merced dataset downloaded and extracted successfully!\")\n",
        "    else:\n",
        "        print(\"UC Merced dataset already downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oABj17_Ir6L"
      },
      "outputs": [],
      "source": [
        "def create_paired_dataset(target_hr_size=256, scale_factor=2):\n",
        "    \"\"\"Creates paired low-resolution and high-resolution images for super-resolution training\"\"\"\n",
        "    lr_images = []\n",
        "    hr_images = []\n",
        "    original_images = []\n",
        "    image_paths = []\n",
        "\n",
        "    lr_size = target_hr_size // scale_factor\n",
        "\n",
        "    for category in SELECTED_CATEGORIES:\n",
        "        category_path = os.path.join(DATASET_PATH, category)\n",
        "        if not os.path.exists(category_path):\n",
        "            print(f\"Warning: Category {category} not found. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        files = os.listdir(category_path)[:SAMPLE_COUNT]\n",
        "\n",
        "        for file in files:\n",
        "            img_path = os.path.join(category_path, file)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is None:\n",
        "                print(f\"Warning: Could not read {file}. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            original_images.append(img.copy())\n",
        "            image_paths.append(img_path)\n",
        "\n",
        "            hr_img = cv2.resize(img, (target_hr_size, target_hr_size))\n",
        "            hr_images.append(hr_img / 255.0)\n",
        "\n",
        "            lr_img = cv2.resize(img, (lr_size, lr_size))\n",
        "            lr_img = cv2.GaussianBlur(lr_img, (3, 3), 0.5)\n",
        "            lr_images.append(lr_img / 255.0)\n",
        "\n",
        "    return (np.array(lr_images, dtype=np.float32),\n",
        "            np.array(hr_images, dtype=np.float32),\n",
        "            original_images,\n",
        "            image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITzepyRhIySb"
      },
      "source": [
        "#Enhancement Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC2myOccI030"
      },
      "outputs": [],
      "source": [
        "class InterpolationMethods:\n",
        "    \"\"\"Traditional interpolation methods for image upscaling\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def bicubic(image, scale=2):\n",
        "        \"\"\"Apply bicubic interpolation to upscale the image\"\"\"\n",
        "        h, w = image.shape[:2]\n",
        "        return cv2.resize(image, (w*scale, h*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    @staticmethod\n",
        "    def lanczos(image, scale=2):\n",
        "        \"\"\"Apply Lanczos interpolation to upscale the image\"\"\"\n",
        "        h, w = image.shape[:2]\n",
        "        return cv2.resize(image, (w*scale, h*scale), interpolation=cv2.INTER_LANCZOS4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qBGHtOAI4_j"
      },
      "outputs": [],
      "source": [
        "class SuperResolutionModel:\n",
        "    \"\"\"Deep learning-based super-resolution model\"\"\"\n",
        "    @staticmethod\n",
        "    def build_generator(scale_factor=2):\n",
        "        \"\"\"Build a super-resolution generator model based on CNN architecture\"\"\"\n",
        "        input_layer = Input(shape=(None, None, 3))\n",
        "\n",
        "        x = Conv2D(64, (3, 3), padding=\"same\")(input_layer)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        for _ in range(8):\n",
        "            skip = x\n",
        "            x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = LeakyReLU(alpha=0.2)(x)\n",
        "            x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = tf.keras.layers.add([x, skip])\n",
        "\n",
        "        if scale_factor > 1:\n",
        "            for _ in range(int(np.log2(scale_factor))):\n",
        "                x = UpSampling2D(size=2)(x)\n",
        "                x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "                x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = Conv2D(3, (3, 3), padding=\"same\", activation=\"sigmoid\")(x)\n",
        "\n",
        "        model = Model(input_layer, x)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def train(model, lr_images, hr_images, epochs=10, batch_size=16):\n",
        "        \"\"\"Train the super-resolution model\"\"\"\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss=\"mse\")\n",
        "\n",
        "        history = model.fit(\n",
        "            lr_images, hr_images,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=0.2,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c63boSLDJAPs"
      },
      "outputs": [],
      "source": [
        "class EnhancementMethods:\n",
        "    \"\"\"Image enhancement techniques\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def wavelet_sharpening(image):\n",
        "        \"\"\"Apply wavelet-based sharpening to enhance image details\"\"\"\n",
        "        img_float = image.astype(np.float32)\n",
        "\n",
        "        if len(img_float.shape) == 3:\n",
        "            r, g, b = cv2.split(img_float)\n",
        "            r_coeffs = pywt.dwt2(r, 'haar')\n",
        "            g_coeffs = pywt.dwt2(g, 'haar')\n",
        "            b_coeffs = pywt.dwt2(b, 'haar')\n",
        "            r_sharp = pywt.idwt2((r_coeffs[0], (r_coeffs[1][0]*1.5, r_coeffs[1][1]*1.5, r_coeffs[1][2]*1.5)), 'haar')\n",
        "            g_sharp = pywt.idwt2((g_coeffs[0], (g_coeffs[1][0]*1.5, g_coeffs[1][1]*1.5, g_coeffs[1][2]*1.5)), 'haar')\n",
        "            b_sharp = pywt.idwt2((b_coeffs[0], (b_coeffs[1][0]*1.5, b_coeffs[1][1]*1.5, b_coeffs[1][2]*1.5)), 'haar')\n",
        "            sharpened = cv2.merge([r_sharp, g_sharp, b_sharp])\n",
        "        else:\n",
        "            coeffs = pywt.dwt2(img_float, 'haar')\n",
        "            sharpened = pywt.idwt2((coeffs[0], (coeffs[1][0]*1.5, coeffs[1][1]*1.5, coeffs[1][2]*1.5)), 'haar')\n",
        "\n",
        "        return np.clip(sharpened, 0, 255).astype(np.uint8)\n",
        "\n",
        "    @staticmethod\n",
        "    def wiener_filter(image, kernel_size=(5, 5)):\n",
        "\n",
        "        def safe_wiener(channel):\n",
        "            # Ensure float32 for processing\n",
        "            channel = channel.astype(np.float32)\n",
        "            # Apply Wiener filter\n",
        "            filtered = wiener(channel, kernel_size)\n",
        "            # Replace NaNs and Infs with zeros or safe values\n",
        "            filtered = np.nan_to_num(filtered, nan=0.0, posinf=255.0, neginf=0.0)\n",
        "            # Clip and convert back\n",
        "            return np.clip(filtered, 0, 255).astype(np.uint8)\n",
        "\n",
        "        if len(image.shape) == 3:\n",
        "            r, g, b = cv2.split(image)\n",
        "            r_deblurred = safe_wiener(r)\n",
        "            g_deblurred = safe_wiener(g)\n",
        "            b_deblurred = safe_wiener(b)\n",
        "            deblurred = cv2.merge([r_deblurred, g_deblurred, b_deblurred])\n",
        "        else:\n",
        "            deblurred = safe_wiener(image)\n",
        "\n",
        "        return deblurred\n",
        "\n",
        "    # Novel Hybrid Methods\n",
        "    @staticmethod\n",
        "    def wavelet_sr_hybrid(sr_image):\n",
        "        \"\"\"Combine Super-Resolution with Wavelet Sharpening\"\"\"\n",
        "        img_uint8 = (sr_image * 255).astype(np.uint8)\n",
        "        sharpened = EnhancementMethods.wavelet_sharpening(img_uint8)\n",
        "        return sharpened.astype(np.float32) / 255.0\n",
        "\n",
        "    @staticmethod\n",
        "    def wiener_sr_hybrid(sr_image):\n",
        "        \"\"\"Combine Super-Resolution with Wiener Filter\"\"\"\n",
        "        img_uint8 = (sr_image * 255).astype(np.uint8)\n",
        "        deblurred = EnhancementMethods.wiener_filter(img_uint8)\n",
        "        return deblurred.astype(np.float32) / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qzy1HWCRJJ-6"
      },
      "source": [
        "#Evaluation Metrics:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcQ7WllyJM-a"
      },
      "outputs": [],
      "source": [
        "\"\"\"#Evaluation Metrics:-\"\"\"\n",
        "\n",
        "#========== EVALUATION METRICS ==========\n",
        "\n",
        "class EvaluationMetrics:\n",
        "    \"\"\"Methods to evaluate image enhancement quality\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_psnr(img1, img2):\n",
        "        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n",
        "        return psnr(img1, img2)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_ssim(img1, img2):\n",
        "        \"\"\"Calculate Structural Similarity Index\"\"\"\n",
        "        return ssim(img1, img2, data_range=1.0, channel_axis=-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_mse(img1, img2):\n",
        "        \"\"\"Calculate Mean Squared Error\"\"\"\n",
        "        return np.mean((img1 - img2) ** 2)\n",
        "\n",
        "    @staticmethod\n",
        "    def evaluate_method(enhanced_images, reference_images, method_name):\n",
        "        \"\"\"Evaluate a method using multiple metrics\"\"\"\n",
        "        ssim_values = []\n",
        "        psnr_values = []\n",
        "        mse_values = []\n",
        "\n",
        "        for i in range(len(enhanced_images)):\n",
        "            img1 = enhanced_images[i].astype(np.float32) / 255.0 if enhanced_images[i].max() > 1.0 else enhanced_images[i].astype(np.float32)\n",
        "            img2 = reference_images[i].astype(np.float32) / 255.0 if reference_images[i].max() > 1.0 else reference_images[i].astype(np.float32)\n",
        "\n",
        "            ssim_values.append(EvaluationMetrics.calculate_ssim(img1, img2))\n",
        "            psnr_values.append(EvaluationMetrics.calculate_psnr(img1, img2))\n",
        "            mse_values.append(EvaluationMetrics.calculate_mse(img1, img2))\n",
        "\n",
        "        return {\n",
        "            \"method\": method_name,\n",
        "            \"ssim\": np.mean(ssim_values),\n",
        "            \"psnr\": np.mean(psnr_values),\n",
        "            \"mse\": np.mean(mse_values)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkefuXmMJTDR"
      },
      "source": [
        "#Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIRg21ldJVTB"
      },
      "outputs": [],
      "source": [
        "\"\"\"#Visualization Functions\"\"\"\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training history of the super-resolution model\"\"\"\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'training_history.png'))\n",
        "    plt.close()\n",
        "\n",
        "def visualize_enhancement_methods(images, enhanced_images, method_names, image_index=0):\n",
        "    \"\"\"Visualize original and enhanced images\"\"\"\n",
        "    n_methods = len(method_names)\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.subplot(2, n_methods, 1)\n",
        "    plt.imshow(images[image_index])\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "    for i, method_name in enumerate(method_names):\n",
        "        plt.subplot(2, n_methods, i+2)\n",
        "        plt.imshow(enhanced_images[i][image_index])\n",
        "        plt.title(method_name)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f'enhancement_comparison_{image_index}.png'))\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(metrics_results):\n",
        "    \"\"\"Plot comparison of metrics for different methods\"\"\"\n",
        "    methods = [result['method'] for result in metrics_results]\n",
        "    ssim_values = [result['ssim'] for result in metrics_results]\n",
        "    psnr_values = [result['psnr'] for result in metrics_results]\n",
        "    mse_values = [result['mse'] for result in metrics_results]\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    bars = plt.bar(methods, ssim_values, color='skyblue')\n",
        "    plt.title('SSIM Comparison (higher is better)')\n",
        "    plt.ylabel('SSIM')\n",
        "    plt.xticks(rotation=45)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    bars = plt.bar(methods, psnr_values, color='lightgreen')\n",
        "    plt.title('PSNR Comparison (higher is better)')\n",
        "    plt.ylabel('PSNR (dB)')\n",
        "    plt.xticks(rotation=45)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.2f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    bars = plt.bar(methods, mse_values, color='salmon')\n",
        "    plt.title('MSE Comparison (lower is better)')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.xticks(rotation=45)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.4f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'metrics_comparison.png'))\n",
        "    plt.close()\n",
        "\n",
        "def plot_processing_times(method_names, processing_times):\n",
        "    \"\"\"Plot processing times for different methods\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    bars = plt.bar(method_names, processing_times, color='lightcoral')\n",
        "    plt.title('Processing Time Comparison')\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.xlabel('Enhancement Method')\n",
        "    plt.xticks(rotation=45)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.2f}s', ha='center', va='bottom')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'processing_time_comparison.png'))\n",
        "    plt.close()\n",
        "\n",
        "def compare_degradation_levels(hr_images, lr_datasets, downscale_factors, sample_index=0):\n",
        "    \"\"\"Visualize and compare different degradation levels on the same image\"\"\"\n",
        "    plt.figure(figsize=(len(downscale_factors) * 4 + 4, 8))\n",
        "    plt.subplot(2, len(downscale_factors) + 1, 1)\n",
        "    plt.imshow(hr_images[sample_index])\n",
        "    plt.title(\"Original (HR)\")\n",
        "    plt.axis('off')\n",
        "    for i, factor in enumerate(downscale_factors):\n",
        "        plt.subplot(2, len(downscale_factors) + 1, i + 2)\n",
        "        plt.imshow(lr_datasets[factor][sample_index])\n",
        "        plt.title(f\"{factor}x Downsampled\")\n",
        "        plt.axis('off')\n",
        "    plt.subplot(2, len(downscale_factors) + 1, len(downscale_factors) + 2)\n",
        "    plt.imshow(np.ones_like(hr_images[sample_index]) * 0.5)\n",
        "    plt.title(\"Difference Maps\")\n",
        "    plt.axis('off')\n",
        "    for i, factor in enumerate(downscale_factors):\n",
        "        diff = np.abs(hr_images[sample_index] - lr_datasets[factor][sample_index]) * 3\n",
        "        diff = np.clip(diff, 0, 1)\n",
        "        plt.subplot(2, len(downscale_factors) + 1, len(downscale_factors) + i + 3)\n",
        "        plt.imshow(diff)\n",
        "        plt.title(f\"{factor}x Diff Map\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f'degradation_comparison_{sample_index}.png'))\n",
        "    plt.close()\n",
        "    print(\"\\nDegradation Level Metrics:\")\n",
        "    for factor in downscale_factors:\n",
        "        ssim_val = EvaluationMetrics.calculate_ssim(lr_datasets[factor][sample_index], hr_images[sample_index])\n",
        "        psnr_val = EvaluationMetrics.calculate_psnr(lr_datasets[factor][sample_index], hr_images[sample_index])\n",
        "        print(f\"{factor}x Downsampling: SSIM={ssim_val:.4f}, PSNR={psnr_val:.2f}dB\")\n",
        "\n",
        "def visualize_sr_results(lr_images, hr_images, enhanced_images, method_names, sample_indices=[0, 1, 2]):\n",
        "    \"\"\"Visualize super-resolution results\"\"\"\n",
        "    n_methods = len(method_names)\n",
        "    for idx in sample_indices:\n",
        "        if idx >= len(lr_images):\n",
        "            continue\n",
        "        plt.figure(figsize=(20, 10))\n",
        "        lr_display = cv2.resize(lr_images[idx], (hr_images[idx].shape[1], hr_images[idx].shape[0]))\n",
        "        plt.subplot(2, n_methods + 1, 1)\n",
        "        plt.imshow(lr_display)\n",
        "        plt.title(\"Low Resolution Input\")\n",
        "        plt.axis('off')\n",
        "        plt.subplot(2, n_methods + 1, n_methods + 2)\n",
        "        plt.imshow(hr_images[idx])\n",
        "        plt.title(\"High Resolution Ground Truth\")\n",
        "        plt.axis('off')\n",
        "        for i, method_name in enumerate(method_names):\n",
        "            plt.subplot(2, n_methods + 1, i + 2)\n",
        "            plt.imshow(enhanced_images[i][idx])\n",
        "            plt.title(method_name)\n",
        "            plt.axis('off')\n",
        "            ssim_val = EvaluationMetrics.calculate_ssim(enhanced_images[i][idx], hr_images[idx])\n",
        "            psnr_val = EvaluationMetrics.calculate_psnr(enhanced_images[i][idx], hr_images[idx])\n",
        "            plt.xlabel(f\"SSIM: {ssim_val:.3f}, PSNR: {psnr_val:.2f}dB\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(RESULTS_DIR, f'sr_comparison_{idx}.png'))\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTzAiENSJaIJ"
      },
      "source": [
        "#Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iiwkd4OJbcK",
        "outputId": "c0b5808e-b32b-4b0a-d704-e9627ae7997e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading UC Merced dataset...\n",
            "Extracting dataset...\n",
            "UC Merced dataset downloaded and extracted successfully!\n",
            "Loading dataset with 2x super-resolution scale...\n",
            "Loaded 1000 images from 10 categories\n",
            "LR shape: (128, 128, 3), HR shape: (256, 256, 3)\n",
            "Applying Bicubic interpolation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Bicubic Interpolation: 100%|██████████| 1000/1000 [00:00<00:00, 3096.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying Lanczos interpolation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Lanczos Interpolation: 100%|██████████| 1000/1000 [00:00<00:00, 1166.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Super-Resolution model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 178ms/step - loss: 0.0427 - val_loss: 0.0602\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 153ms/step - loss: 0.0077 - val_loss: 0.0498\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 158ms/step - loss: 0.0058 - val_loss: 0.0373\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 155ms/step - loss: 0.0048 - val_loss: 0.0287\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - loss: 0.0043 - val_loss: 0.0148\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - loss: 0.0044 - val_loss: 0.0094\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - loss: 0.0036 - val_loss: 0.0063\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 164ms/step - loss: 0.0041 - val_loss: 0.0063\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 0.0034 - val_loss: 0.0047\n",
            "Super-Resolution model saved to sr_model_files/sr_model_x2.keras\n",
            "Applying Super-Resolution model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Super-Resolution Prediction: 100%|██████████| 63/63 [00:17<00:00,  3.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying Wavelet Sharpening...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Wavelet Sharpening: 100%|██████████| 1000/1000 [00:07<00:00, 136.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying Wiener Filter...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Wiener Filter: 100%|██████████| 1000/1000 [00:18<00:00, 55.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying Wavelet-SR Hybrid...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Wavelet-SR Hybrid: 100%|██████████| 1000/1000 [00:07<00:00, 138.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying Wiener-SR Hybrid...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Wiener-SR Hybrid: 100%|██████████| 1000/1000 [00:18<00:00, 53.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating all methods...\n",
            "Bicubic: SSIM=0.6756, PSNR=26.49dB, MSE=0.069530\n",
            "Lanczos: SSIM=0.6963, PSNR=27.02dB, MSE=0.064853\n",
            "Super-Resolution: SSIM=0.8456, PSNR=27.07dB, MSE=0.002539\n",
            "Wavelet: SSIM=0.8126, PSNR=28.49dB, MSE=0.002618\n",
            "Wiener: SSIM=0.6949, PSNR=26.43dB, MSE=0.004028\n",
            "Wavelet-SR: SSIM=0.8221, PSNR=26.39dB, MSE=0.002962\n",
            "Wiener-SR: SSIM=0.7447, PSNR=26.00dB, MSE=0.003429\n",
            "Generating visualizations...\n",
            "All results saved to enhancement_results directory\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    download_uc_merced()\n",
        "\n",
        "    # Create a specific directory for models\n",
        "    MODEL_SAVE_DIR = \"sr_model_files\"\n",
        "    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    hr_size = 256\n",
        "    scale_factor = 2\n",
        "\n",
        "    print(f\"Loading dataset with {scale_factor}x super-resolution scale...\")\n",
        "    lr_images, hr_images, original_images, image_paths = create_paired_dataset(\n",
        "        target_hr_size=hr_size,\n",
        "        scale_factor=scale_factor\n",
        "    )\n",
        "\n",
        "    print(f\"Loaded {len(lr_images)} images from {len(SELECTED_CATEGORIES)} categories\")\n",
        "    print(f\"LR shape: {lr_images[0].shape}, HR shape: {hr_images[0].shape}\")\n",
        "\n",
        "    method_names = [\n",
        "        \"Bicubic\", \"Lanczos\", \"Super-Resolution\",\n",
        "        \"Wavelet\", \"Wiener\",\n",
        "        \"Wavelet-SR\", \"Wiener-SR\"\n",
        "    ]\n",
        "    enhanced_images = [[] for _ in range(len(method_names))]\n",
        "    metrics_results = []\n",
        "    processing_times = []\n",
        "\n",
        "    # Apply bicubic interpolation\n",
        "    print(\"Applying Bicubic interpolation...\")\n",
        "    start_time = time.time()\n",
        "    for lr_img in tqdm(lr_images, desc=\"Bicubic Interpolation\"):\n",
        "        enhanced = InterpolationMethods.bicubic(lr_img, scale=scale_factor)\n",
        "        enhanced_images[0].append(enhanced)\n",
        "    processing_times.append(time.time() - start_time)\n",
        "\n",
        "    # Apply Lanczos interpolation\n",
        "    print(\"Applying Lanczos interpolation...\")\n",
        "    start_time = time.time()\n",
        "    for lr_img in tqdm(lr_images, desc=\"Lanczos Interpolation\"):\n",
        "        enhanced = InterpolationMethods.lanczos(lr_img, scale=scale_factor)\n",
        "        enhanced_images[1].append(enhanced)\n",
        "    processing_times.append(time.time() - start_time)\n",
        "\n",
        "    # Train and apply Super-Resolution model\n",
        "    print(\"Training Super-Resolution model...\")\n",
        "    generator = SuperResolutionModel.build_generator(scale_factor=scale_factor)\n",
        "    history = SuperResolutionModel.train(generator, lr_images, hr_images, epochs=10, batch_size=8)\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Save the trained model with the proper extension\n",
        "    model_save_path = os.path.join(MODEL_SAVE_DIR, f\"sr_model_x{scale_factor}.keras\")\n",
        "    generator.save(model_save_path)\n",
        "    print(f\"Super-Resolution model saved to {model_save_path}\")\n",
        "\n",
        "    print(\"Applying Super-Resolution model...\")\n",
        "    start_time = time.time()\n",
        "    for i in tqdm(range(0, len(lr_images), BATCH_SIZE), desc=\"Super-Resolution Prediction\"):\n",
        "        batch_lr = lr_images[i:i + BATCH_SIZE]\n",
        "        batch_lr = np.array(batch_lr)\n",
        "        predictions = generator.predict(batch_lr, batch_size=BATCH_SIZE, verbose=0)\n",
        "        for sr_img in predictions:\n",
        "            sr_img = np.clip(sr_img, 0, 1)\n",
        "            enhanced_images[2].append(sr_img)\n",
        "    processing_times.append(time.time() - start_time)\n",
        "\n",
        "    # Upscale LR images for traditional enhancement methods\n",
        "    upscaled_lr_images = []\n",
        "    for lr_img in lr_images:\n",
        "        upscaled = cv2.resize(lr_img, (hr_size, hr_size))\n",
        "        upscaled_lr_images.append(upscaled)\n",
        "\n",
        "    # Apply Wavelet Sharpening\n",
        "    print(\"Applying Wavelet Sharpening...\")\n",
        "    start_time = time.time()\n",
        "    for img in tqdm(upscaled_lr_images, desc=\"Wavelet Sharpening\"):\n",
        "        img_uint8 = (img * 255).astype(np.uint8)\n",
        "        enhanced = EnhancementMethods.wavelet_sharpening(img_uint8)\n",
        "        enhanced = enhanced.astype(np.float32) / 255.0\n",
        "        enhanced_images[3].append(enhanced)\n",
        "    processing_times.append(time.time() - start_time)\n",
        "\n",
        "    # Apply Wiener Filter\n",
        "    print(\"Applying Wiener Filter...\")\n",
        "    start_time = time.time()\n",
        "    for img in tqdm(upscaled_lr_images, desc=\"Wiener Filter\"):\n",
        "        img_uint8 = (img * 255).astype(np.uint8)\n",
        "        enhanced = EnhancementMethods.wiener_filter(img_uint8)\n",
        "        enhanced = enhanced.astype(np.float32) / 255.0\n",
        "        enhanced_images[4].append(enhanced)\n",
        "    processing_times.append(time.time() - start_time)\n",
        "\n",
        "    # Apply Novel Hybrid Methods\n",
        "    print(\"Applying Wavelet-SR Hybrid...\")\n",
        "    start_time = time.time()\n",
        "    for sr_img in tqdm(enhanced_images[2], desc=\"Wavelet-SR Hybrid\"):\n",
        "        enhanced = EnhancementMethods.wavelet_sr_hybrid(sr_img)\n",
        "        enhanced_images[5].append(enhanced)\n",
        "    processing_times.append(time.time() - start_time)\n",
        "\n",
        "    print(\"Applying Wiener-SR Hybrid...\")\n",
        "    start_time = time.time()\n",
        "    for sr_img in tqdm(enhanced_images[2], desc=\"Wiener-SR Hybrid\"):\n",
        "        enhanced = EnhancementMethods.wiener_sr_hybrid(sr_img)\n",
        "        enhanced_images[6].append(enhanced)\n",
        "    processing_times.append(time.time() - start_time)\n",
        "\n",
        "    # Evaluate all methods\n",
        "    print(\"Evaluating all methods...\")\n",
        "    for i, method_name in enumerate(method_names):\n",
        "        results = EvaluationMetrics.evaluate_method(enhanced_images[i], hr_images, method_name)\n",
        "        metrics_results.append(results)\n",
        "        print(f\"{method_name}: SSIM={results['ssim']:.4f}, PSNR={results['psnr']:.2f}dB, MSE={results['mse']:.6f}\")\n",
        "\n",
        "    # Visualize results\n",
        "    print(\"Generating visualizations...\")\n",
        "    visualize_sr_results(lr_images, hr_images, enhanced_images, method_names)\n",
        "\n",
        "    # Plot metrics comparison\n",
        "    plot_metrics_comparison(metrics_results)\n",
        "\n",
        "    # Plot processing times\n",
        "    plot_processing_times(method_names, processing_times)\n",
        "\n",
        "    print(f\"All results saved to {RESULTS_DIR} directory\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
